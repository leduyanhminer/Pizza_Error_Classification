{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i>Download images</i></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DuyAnh\\AppData\\Local\\Temp\\ipykernel_17136\\1234846730.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('pizza_data_final.csv', index_col='id')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('pizza_data_final.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_error_list = ['Bánh không tròn | Distorted shape',\n",
    " 'Cháy | Baking - Burnt',\n",
    " 'Viền k đều | Edge - Uneven',\n",
    " 'Bánh bé | Size - Too small',\n",
    " 'Thiếu bóng | too few balls',\n",
    " 'Không đốm | Baking - Does not have leopard-spotting',\n",
    " 'Màu nhạt | Baking - Pale',\n",
    " 'Viền nhỏ | Edge - Too small',\n",
    " 'Viền to | Edge - Too big',\n",
    " 'Nở viền không đủ | edge pizza is not enough swollen',\n",
    " 'Viền thấp | Edge - Too low',\n",
    " 'Phô mai cao | Topping - Cheese too high * with a core*',\n",
    " 'Topping - Không đúng | incorrect portioning',\n",
    " 'Không cân Topping - Not even half and half',\n",
    " 'Sốt trên mép | Topping - Sauce covering on the edge',\n",
    " 'Lên men thiếu | Fermentation - Lack fermentation',\n",
    " 'Quá theo viền | Topping - Too strong shaping the edge',\n",
    " 'Trộn lẫn | Topping - Bended',\n",
    " 'Quá tập trung | Topping - Topping too centered',\n",
    " 'Topping - Không đều | Not even',\n",
    " 'Lên men quá nhiều | Fermentation - Over fermentation',\n",
    " 'Không hình tròn | Topping - Not circled',\n",
    " 'Bánh lớn | Size - Too big']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_download_image = []\n",
    "for error in all_error_list:\n",
    "    error_df = df[df[error] == 1].head(200)\n",
    "    for image_id, image_url in zip(error_df.index, error_df['image_url']):\n",
    "        queue_download_image.append((image_id, image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/pizza_image'\n",
    "# downloaded = []\n",
    "# for id, url in tqdm(queue_download_image):\n",
    "#     if id not in downloaded:\n",
    "#         downloaded.append(id)\n",
    "#         response = requests.get(url)\n",
    "#         image_data = BytesIO(response.content)\n",
    "#         image = Image.open(image_data)\n",
    "#         image_file_name = os.path.join(data_path, f\"{id}.jpg\")\n",
    "#         image.save(image_file_name)\n",
    "#         if response.status_code == 200:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(f\"Failed to download {image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4126/4126 [01:33<00:00, 44.01it/s]\n"
     ]
    }
   ],
   "source": [
    "images = {}\n",
    "dict_labels = {}\n",
    "for id, _ in tqdm(queue_download_image):\n",
    "    images[id] = np.array(Image.open(f'data/pizza_image/{id}.jpg'))\n",
    "    dict_labels[id] = []\n",
    "    for error in all_error_list:\n",
    "        dict_labels[id].append(df.at[id, error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0 11  5]\n",
      "  [ 4 15  7]\n",
      "  [ 8 19 11]\n",
      "  ...\n",
      "  [ 0  4 15]\n",
      "  [ 0  4 13]\n",
      "  [ 0  4 13]]\n",
      "\n",
      " [[ 8 17 12]\n",
      "  [ 9 20 14]\n",
      "  [11 21 13]\n",
      "  ...\n",
      "  [ 0  3 12]\n",
      "  [ 0  3 12]\n",
      "  [ 0  3 10]]\n",
      "\n",
      " [[12 18 14]\n",
      "  [10 19 14]\n",
      "  [11 18 11]\n",
      "  ...\n",
      "  [ 0  0 10]\n",
      "  [ 0  0  8]\n",
      "  [ 0  1  6]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[39 43 55]\n",
      "  [33 35 50]\n",
      "  [31 30 48]\n",
      "  ...\n",
      "  [13  7 43]\n",
      "  [10  4 42]\n",
      "  [12  8 45]]\n",
      "\n",
      " [[41 45 56]\n",
      "  [43 45 57]\n",
      "  [45 44 58]\n",
      "  ...\n",
      "  [17 13 50]\n",
      "  [13  9 44]\n",
      "  [19 18 52]]\n",
      "\n",
      " [[38 42 51]\n",
      "  [47 50 59]\n",
      "  [52 51 65]\n",
      "  ...\n",
      "  [11  9 46]\n",
      "  [ 6  5 39]\n",
      "  [17 16 50]]] [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(images['644b407dba8c270029f69526'], dict_labels['644b407dba8c270029f69526'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained = True)\n",
    "num_classes = 23\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1024, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, num_classes),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def transform_image(image):\n",
    "    image = Image.fromarray(image)\n",
    "    img_tensor = transform(image)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:48<00:00, 22.19it/s]\n"
     ]
    }
   ],
   "source": [
    "new_images = {}\n",
    "for id, img in tqdm(images.items()):\n",
    "    new_images[id] = transform_image(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_images['644b407dba8c270029f69526'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = []\n",
    "for id, label in dict_labels.items():\n",
    "    new_labels.append(label)\n",
    "\n",
    "new_labels = torch.tensor(new_labels, dtype = torch.float)\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 32\n",
    "X_train, X_test, y_train, y_test = train_test_split(list(new_images.values()), new_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = TensorDataset(torch.stack(X_train), y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(torch.stack(X_test), y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước của train_data: 1932 torch.Size([3, 224, 224]) torch.Size([23])\n",
      "Tổng số batch: 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Kích thước của train_data:\", len(train_data), train_data[0][0].shape, train_data[0][1].shape)\n",
    "print(\"Tổng số batch:\", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [07:15<14:31, 435.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 14.5528, Accuracy: 67.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [14:13<07:04, 424.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 11.0600, Accuracy: 70.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [21:19<00:00, 426.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 11.3137, Accuracy: 67.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "num_epochs = 3\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Đánh giá mô hình (nếu bạn có tập kiểm tra)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.size(0) * 23\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += labels.size(0) * \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Predict pizza image </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_tensor):\n",
    "    img_tensor = img_tensor.unsqueeze(dim = 0)\n",
    "    predicted = model(img_tensor)\n",
    "    predicted = torch.round(predicted)\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4126/4126 [00:01<00:00, 3431.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_labels = {}\n",
    "for id, _ in tqdm(queue_download_image):\n",
    "    dict_labels[id] = []\n",
    "    for error in all_error_list:\n",
    "        dict_labels[id].append(df.at[id, error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]], grad_fn=<RoundBackward0>)\n",
      "[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "my_image_path = 'data/pizza_image/644b4f88ba8c270029f69584.jpg'\n",
    "my_image = np.array(Image.open(my_image_path))\n",
    "my_image_tensor = transform_image(my_image)\n",
    "predict(my_image_tensor)\n",
    "print(dict_labels['644b4f88ba8c270029f69584'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
